{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from netam import shmoof, noof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = shmoof.load_shmoof_dataframes(\"/Users/matsen/data/shmoof_edges_11-Jan-2023_NoNode0_iqtree_K80+R_masked.csv\")# , sample_count=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tang data\n",
    "\n",
    "# full_df = pd.read_csv(\"/Users/matsen/data/tang-deepshm_size2_edges_22-May-2023.branch_length.csv\", index_col=0).reset_index(drop=True)\n",
    "# \n",
    "# # only keep rows where parent is different than child\n",
    "# full_df = full_df[full_df[\"parent\"] != full_df[\"child\"]]\n",
    "# \n",
    "# train_df = full_df.sample(frac=0.8)\n",
    "# val_df = full_df.drop(train_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_length = 5\n",
    "max_length = 410\n",
    "\n",
    "train_dataset = shmoof.SHMoofDataset(train_df, kmer_length=kmer_length, max_length=max_length)\n",
    "val_dataset = shmoof.SHMoofDataset(val_df, kmer_length=kmer_length, max_length=max_length)\n",
    "\n",
    "print(f\"we have {len(train_dataset)} training examples and {len(val_dataset)} validation examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"parent\"].str.len().median()\n",
    "#train_df[\"v_int_end\"].hist(bins=100)\n",
    "# get the index of the maximum True entry of train_dataset[0][1]\n",
    "masks = train_dataset.masks\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_length_of_masks(masks):\n",
    "    batch_size, seq_length = masks.shape\n",
    "\n",
    "    range_tensor = torch.arange(seq_length).repeat(batch_size, 1)\n",
    "    masked_range = torch.where(masks, range_tensor, torch.tensor(-1))\n",
    "\n",
    "    return masked_range.max(dim=1)[0]\n",
    "\n",
    "sequence_length_of_masks(masks).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLengthSHMoofModel(nn.Module):\n",
    "    def __init__(self, dataset, length_threshold, residual_penalty_weight=0.0):\n",
    "        super(TwoLengthSHMoofModel, self).__init__()\n",
    "        self.kmer_count = len(dataset.kmer_to_index)\n",
    "        self.site_count = dataset.max_length\n",
    "        self.length_threshold = length_threshold\n",
    "        self.residual_penalty_weight = residual_penalty_weight\n",
    "\n",
    "        self.kmer_embedding = nn.Embedding(self.kmer_count, 1)\n",
    "        self.log_site_rates = nn.Embedding(self.site_count, 1)\n",
    "        self.log_site_rates_long_residual = nn.Embedding(self.site_count, 1)\n",
    "\n",
    "    def forward(self, encoded_parents, masks):\n",
    "        log_kmer_rates = self.kmer_embedding(encoded_parents).squeeze()\n",
    "        sequence_length = sequence_length_of_masks(masks)\n",
    "\n",
    "        # Determine if the sequence is long or short\n",
    "        is_long = sequence_length > self.length_threshold\n",
    "        is_long = is_long.unsqueeze(-1)\n",
    "\n",
    "        log_site_rates_short = self.log_site_rates.weight.T.expand_as(log_kmer_rates)\n",
    "        # set log_site_rates_short to zero for all indices beyond the length threshold\n",
    "        log_site_rates_short = torch.where(is_long, torch.tensor(0.0), log_site_rates_short)\n",
    "        log_site_rates_long_residual = self.log_site_rates_long_residual.weight.T.expand_as(log_kmer_rates)\n",
    "        \n",
    "        # Adjust log_site_rates for long sequences\n",
    "        log_site_rates_long = log_site_rates_short + log_site_rates_long_residual\n",
    "        log_site_rates = torch.where(is_long, log_site_rates_long, log_site_rates_short)\n",
    "\n",
    "        rates = torch.exp(log_kmer_rates + log_site_rates)\n",
    "        return rates\n",
    "\n",
    "    def regularization_loss(self):\n",
    "        # Calculate L2 norm (squared sum) of the log_site_rates_long_residual weights\n",
    "        reg_loss = torch.sum(self.log_site_rates_long_residual.weight ** 2)\n",
    "        # Apply the regularization weight\n",
    "        reg_loss *= self.residual_penalty_weight\n",
    "        return reg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_threshold = sequence_length_of_masks(masks).median()\n",
    "model = TwoLengthSHMoofModel(train_dataset, length_threshold=length_threshold, residual_penalty_weight=1e-5)\n",
    "burrito = shmoof.NoofBurrito(train_dataset, val_dataset, model, batch_size=1024, learning_rate=0.1, l2_regularization_coeff=1e-6)\n",
    "print(\"starting training...\")\n",
    "losses = burrito.train(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load motif mutabilities\n",
    "shmoof_motifs = pd.read_csv('_ignore/original_shmoof/mutabilities_context.tsv', sep='\\t')\n",
    "# rename Mutability column to Mutability_shmoof\n",
    "#shmoof_motifs = shmoof_motifs.rename(columns={'Mutability': 'Mutability_shmoof'})\n",
    "reshmoof_mutabilities = torch.exp(model.kmer_embedding.weight).squeeze().detach().numpy()\n",
    "reshmoof_motifs = pd.DataFrame({'Mutability': reshmoof_mutabilities, 'Motif': train_dataset.kmer_to_index.keys()})\n",
    "\n",
    "# Merge dataframes\n",
    "merged_motifs = pd.merge(shmoof_motifs, reshmoof_motifs, on='Motif', how='inner', suffixes=('_shmoof', '_reshmoof'))\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(merged_motifs['Mutability_shmoof'], merged_motifs['Mutability_reshmoof'], alpha=0.5)\n",
    "\n",
    "# Determine bounds for y=x line\n",
    "min_bound = min(merged_motifs['Mutability_shmoof'].min(), merged_motifs['Mutability_reshmoof'].min())\n",
    "max_bound = max(merged_motifs['Mutability_shmoof'].max(), merged_motifs['Mutability_reshmoof'].max())\n",
    "\n",
    "# Add y=x line\n",
    "plt.plot([min_bound, max_bound], [min_bound, max_bound], 'r--')\n",
    "\n",
    "plt.xlabel('Shmoof Mutability')\n",
    "plt.ylabel('Reshmoof Mutability')\n",
    "plt.title('Comparison of Motif Mutabilities: Shmoof vs. Reshmoof')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `model` is your trained model instance\n",
    "log_site_rates_short = model.log_site_rates.weight.data.squeeze().cpu().numpy()\n",
    "log_site_rates_long_residual = model.log_site_rates_long_residual.weight.data.squeeze().cpu().numpy()\n",
    "\n",
    "# Calculate the exponential of the log rates\n",
    "site_rates_short = torch.exp(torch.tensor(log_site_rates_short)).numpy()\n",
    "site_rates_long_residual = torch.exp(torch.tensor(log_site_rates_long_residual)).numpy()\n",
    "\n",
    "# Ensure the site rates are 1-dimensional\n",
    "assert site_rates_short.ndim == 1\n",
    "assert site_rates_long_residual.ndim == 1\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame({\n",
    "    'Position': range(1, len(site_rates_short) + 1),\n",
    "    'Short_Site_Rates': site_rates_short,\n",
    "    'Long_Residual_Site_Rates': site_rates_long_residual\n",
    "})\n",
    "\n",
    "# Line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Position'], df['Short_Site_Rates'], label='Short Site Rates', color='orange')\n",
    "plt.plot(df['Position'], df['Long_Residual_Site_Rates'], label='Long Site Residuals', color='green', alpha=0.5)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Mutability')\n",
    "plt.title(f'Comparison of Short vs. Long Site Rates, residual_penalty_weight={model.residual_penalty_weight}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "regularization_coeffs = [0, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "results = []\n",
    "\n",
    "for coeff in regularization_coeffs:\n",
    "    print(f\"Training with regularization coefficient {coeff}\")\n",
    "    model = shmoof.SHMoofModel(train_dataset)\n",
    "    burrito = shmoof.NoofBurrito(train_dataset, val_dataset, model, batch_size=1024, learning_rate=0.1, l2_regularization_coeff=1e-6)\n",
    "    loss_history = burrito.train(epochs=20)\n",
    "    final_training_loss = loss_history['training_losses'].iloc[-1]\n",
    "    final_validation_loss = loss_history['validation_losses'].iloc[-1]\n",
    "\n",
    "    results.append({\n",
    "        'Regularization': coeff,\n",
    "        'Final_Training_Loss': final_training_loss,\n",
    "        'Final_Validation_Loss': final_validation_loss\n",
    "    })\n",
    "\n",
    "regularization_results_df = pd.DataFrame(results)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(regularization_results_df['Regularization'], regularization_results_df['Final_Training_Loss'], label='Training Loss', marker='o')\n",
    "plt.plot(regularization_results_df['Regularization'], regularization_results_df['Final_Validation_Loss'], label='Validation Loss', marker='x')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Regularization Coefficient')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Effect of L2 Regularization on Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
