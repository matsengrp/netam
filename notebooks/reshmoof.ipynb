{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from netam import shmoof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_shmoof_df = pd.read_csv(\"/Users/matsen/data/shmoof_edges_11-Jan-2023_NoNode0_iqtree_K80+R_masked.csv\", index_col=0).reset_index(drop=True)\n",
    "\n",
    "train_df = full_shmoof_df.sample(frac=0.8)\n",
    "val_df = full_shmoof_df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [359] at entry 0 and [362] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/matsen/re/netam/notebooks/reshmoof.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matsen/re/netam/notebooks/reshmoof.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m burrito \u001b[39m=\u001b[39m shmoof\u001b[39m.\u001b[39;49mSHMoofBurrito(train_df, val_df, max_length\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m, kmer_length\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsen/re/netam/notebooks/reshmoof.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m burrito\u001b[39m.\u001b[39mtrain(epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsen/re/netam/notebooks/reshmoof.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m burrito\u001b[39m.\u001b[39mwrite_shmoof_output(\u001b[39m\"\u001b[39m\u001b[39m_ignore\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/re/netam/netam/shmoof.py:107\u001b[0m, in \u001b[0;36mSHMoofBurrito.__init__\u001b[0;34m(self, train_dataframe, val_dataframe, kmer_length, max_length)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, train_dataframe, val_dataframe, kmer_length\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m):\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset \u001b[39m=\u001b[39m SHMoofDataset(train_dataframe, kmer_length, max_length)\n\u001b[1;32m    108\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_dataset \u001b[39m=\u001b[39m SHMoofDataset(val_dataframe, kmer_length, max_length)\n\u001b[1;32m    110\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m SHMoofModel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset)\n",
      "File \u001b[0;32m~/re/netam/netam/shmoof.py:29\u001b[0m, in \u001b[0;36mSHMoofDataset.__init__\u001b[0;34m(self, dataframe, kmer_length, max_length)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_kmers) \u001b[39m<\u001b[39m torch\u001b[39m.\u001b[39miinfo(torch\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkmer_to_index \u001b[39m=\u001b[39m {kmer: idx \u001b[39mfor\u001b[39;00m idx, kmer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_kmers)}\n\u001b[1;32m     25\u001b[0m (\n\u001b[1;32m     26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoded_parents,\n\u001b[1;32m     27\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasks,\n\u001b[1;32m     28\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutation_vectors,\n\u001b[0;32m---> 29\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_sequences(dataframe)\n",
      "File \u001b[0;32m~/re/netam/netam/shmoof.py:53\u001b[0m, in \u001b[0;36mSHMoofDataset.encode_sequences\u001b[0;34m(self, dataframe)\u001b[0m\n\u001b[1;32m     47\u001b[0m     masks\u001b[39m.\u001b[39mappend(mask)\n\u001b[1;32m     48\u001b[0m     mutation_vectors\u001b[39m.\u001b[39mappend(mutation_indicator)\n\u001b[1;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m     51\u001b[0m     torch\u001b[39m.\u001b[39mstack(encoded_parents),\n\u001b[1;32m     52\u001b[0m     torch\u001b[39m.\u001b[39mstack(masks),\n\u001b[0;32m---> 53\u001b[0m     torch\u001b[39m.\u001b[39;49mstack(mutation_vectors),\n\u001b[1;32m     54\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [359] at entry 0 and [362] at entry 1"
     ]
    }
   ],
   "source": [
    "burrito = shmoof.SHMoofBurrito(train_df, val_df, max_length=300, kmer_length=5)\n",
    "burrito.train(epochs=5)\n",
    "burrito.write_shmoof_output(\"_ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
